{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cb4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from rapidfuzz import fuzz\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007db6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba5d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Similarity Functions ----------\n",
    "def jaccard_similarity(a, b):\n",
    "    a_set, b_set = set(a.split()), set(b.split())\n",
    "    if not a_set or not b_set:\n",
    "        return 0\n",
    "    return len(a_set & b_set) / len(a_set | b_set)\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    vectorizer = CountVectorizer().fit([a, b])\n",
    "    vectors = vectorizer.transform([a, b])\n",
    "    return cosine_similarity(vectors)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e818508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Main Rule-Based Scoring ----------\n",
    "def classify_response(response, correct_answer, high_threshold, low_threshold):\n",
    "    response = str(response).strip().lower()\n",
    "    correct_answer = str(correct_answer).strip().lower()\n",
    "\n",
    "    if response == \"\" or response in [\"idk\", \"i don't know\", \"i dunno\"]:\n",
    "        return -1\n",
    "\n",
    "    fuzzy_ratio = fuzz.token_sort_ratio(response, correct_answer) / 100\n",
    "    jaccard = jaccard_similarity(response, correct_answer)\n",
    "    cosine = cosine_sim(response, correct_answer)\n",
    "\n",
    "    try: \n",
    "        semantic = nlp(response).similarity(nlp(correct_answer)) \n",
    "    except Exception: \n",
    "        semantic = 0 # fallback\n",
    "\n",
    "    resp_nums = re.findall(r\"\\d+\", response)\n",
    "    corr_nums = re.findall(r\"\\d+\", correct_answer)\n",
    "    num_match = 1 if resp_nums and resp_nums == corr_nums else 0\n",
    "\n",
    "    # Weighted total score\n",
    "    total_score = (\n",
    "        fuzzy_ratio\n",
    "    )\n",
    "\n",
    "    # Threshold-based classification\n",
    "    if total_score > high_threshold:\n",
    "        return 1\n",
    "    elif total_score > low_threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a8cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.6, low=0.55 ‚Üí Accuracy=72.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.6, low=0.56 ‚Üí Accuracy=73.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.6, low=0.57 ‚Üí Accuracy=73.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.6, low=0.58 ‚Üí Accuracy=73.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.6, low=0.59 ‚Üí Accuracy=73.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.61, low=0.55 ‚Üí Accuracy=72.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.61, low=0.56 ‚Üí Accuracy=72.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.61, low=0.57 ‚Üí Accuracy=72.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.61, low=0.58 ‚Üí Accuracy=73.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.61, low=0.59 ‚Üí Accuracy=73.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.61, low=0.6 ‚Üí Accuracy=73.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.55 ‚Üí Accuracy=71.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.56 ‚Üí Accuracy=72.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.57 ‚Üí Accuracy=72.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.58 ‚Üí Accuracy=72.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.59 ‚Üí Accuracy=73.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.6 ‚Üí Accuracy=73.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.62, low=0.61 ‚Üí Accuracy=73.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.55 ‚Üí Accuracy=71.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.56 ‚Üí Accuracy=71.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.57 ‚Üí Accuracy=71.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.58 ‚Üí Accuracy=72.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.59 ‚Üí Accuracy=72.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.6 ‚Üí Accuracy=72.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.61 ‚Üí Accuracy=72.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.63, low=0.62 ‚Üí Accuracy=72.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.55 ‚Üí Accuracy=70.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.56 ‚Üí Accuracy=71.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.57 ‚Üí Accuracy=71.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.58 ‚Üí Accuracy=71.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.59 ‚Üí Accuracy=72.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.6 ‚Üí Accuracy=72.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.61 ‚Üí Accuracy=72.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.62 ‚Üí Accuracy=72.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.64, low=0.63 ‚Üí Accuracy=72.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.55 ‚Üí Accuracy=70.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.56 ‚Üí Accuracy=70.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.57 ‚Üí Accuracy=71.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.58 ‚Üí Accuracy=71.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.59 ‚Üí Accuracy=71.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.6 ‚Üí Accuracy=71.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.61 ‚Üí Accuracy=71.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.62 ‚Üí Accuracy=72.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.63 ‚Üí Accuracy=72.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Kam\\AppData\\Local\\Temp\\ipykernel_22692\\3143580943.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  semantic = nlp(response).similarity(nlp(correct_answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested: high=0.65, low=0.64 ‚Üí Accuracy=72.27%\n"
     ]
    }
   ],
   "source": [
    "# ---------- Main Loop ----------\n",
    "df = pd.read_csv(\"train_cleaned.csv\", encoding=\"latin1\")\n",
    "results = []\n",
    "\n",
    "for high_threshold in [round(x, 2) for x in np.arange(0.60, 0.651, 0.01)]:\n",
    "    for low_threshold in [round(x, 2) for x in np.arange(0.55, high_threshold, 0.01)]:\n",
    "        temp_df = df.copy()\n",
    "\n",
    "        temp_df[\"Predicted_Label\"] = temp_df.apply(\n",
    "            lambda row: classify_response(row[\"Response\"], row[\"CorrectAnswer\"], high_threshold, low_threshold),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        if \"label\" in temp_df.columns:\n",
    "            total_rows = len(temp_df)\n",
    "            correct_predictions = (temp_df[\"Predicted_Label\"] == temp_df[\"label\"]).sum()\n",
    "            accuracy = correct_predictions / total_rows * 100\n",
    "        else:\n",
    "            accuracy = 0\n",
    "\n",
    "        print(f\"Tested: high={high_threshold}, low={low_threshold} ‚Üí Accuracy={accuracy:.2f}%\")\n",
    "\n",
    "        results.append({\n",
    "            \"result_1_limit\": high_threshold,\n",
    "            \"result_0_limit\": low_threshold,\n",
    "            \"accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "        temp_df.to_csv(\"train_responses.csv\", index=False)\n",
    "\n",
    "        # Delete temp file\n",
    "        if os.path.exists(\"train_responses.csv\"):\n",
    "            os.remove(\"train_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0acb7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All threshold combinations tested.\n",
      "üìÑ Results saved to 'threshold_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Save Final Summary ----------\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"threshold_results_train.csv\", index=False)\n",
    "print(\"\\n‚úÖ All threshold combinations tested.\")\n",
    "print(\"üìÑ Results saved to 'threshold_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab89de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best thresholds found:\n",
      "Result=1 limit: 0.6\n",
      "Result=0 limit: 0.59\n",
      "Accuracy: 73.87%\n"
     ]
    }
   ],
   "source": [
    "# ---------- Print Best Thresholds ----------\n",
    "best = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "print(f\"\\nüèÜ Best thresholds found:\")\n",
    "print(f\"Result=1 limit: {best['result_1_limit']}\")\n",
    "print(f\"Result=0 limit: {best['result_0_limit']}\")\n",
    "print(f\"Accuracy: {best['accuracy']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
